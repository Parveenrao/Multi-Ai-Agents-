{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1hZnQAGmeaj",
        "outputId": "0925c900-f623-44aa-ed12-0de66e326f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.39-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.4,>=0.2.39 (from langgraph)\n",
            "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.33-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m580.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.32.3)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4,>=0.2.39->langgraph)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Collecting httpx-sse>=0.4.0 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.2.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n",
            "Downloading langgraph-0.2.39-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading langgraph_sdk-0.1.33-py3-none-any.whl (28 kB)\n",
            "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, httpx-sse, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.12 langgraph-0.2.39 langgraph-checkpoint-2.0.1 langgraph-sdk-0.1.33 langsmith-0.1.137 orjson-3.10.10 requests-toolbelt-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqGFHz_TnAtb",
        "outputId": "60d2812c-783d-475c-c3e2-15b5fbe22177"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.3.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.4 (from langchain_community)\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.15.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.4->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_groq) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_groq) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Downloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, groq, dataclasses-json, langchain-text-splitters, langchain_groq, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.11.0 langchain-0.3.4 langchain-text-splitters-0.3.0 langchain_community-0.3.3 langchain_groq-0.2.0 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "Groq_Api_Key  = userdata.get('Groq_Api_Key')\n",
        "Langsmith_Api_Key = userdata.get('Langsmith_Api_Key')\n"
      ],
      "metadata": {
        "id": "8dJ-HrlqnKlX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = Groq_Api_Key\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_Api_KeyT\"] = Langsmith_Api_Key\n",
        "os.environ[\"LANGCHAIN_Project\"] = \"Course_Langgraph \""
      ],
      "metadata": {
        "id": "nP8c-ESXpSk0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm  = ChatGroq(groq_api_key=Groq_Api_Key , model = \"Gemma2-9b-It\")"
      ],
      "metadata": {
        "id": "4oBHgtlbq9FF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot Using Langgraph"
      ],
      "metadata": {
        "id": "_DzBziw8r3Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "-DpbYIjAr6iI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "  message:Annotated[list , add_messages]"
      ],
      "metadata": {
        "id": "EMQDuDJTtMi3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "BX59RODst6Dm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State):\n",
        "  return{'message': llm.invoke(state['message'])}"
      ],
      "metadata": {
        "id": "RNSEzOP4uKf4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node('Chatbot' , chatbot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJoJ9i0WutoO",
        "outputId": "64ac1b26-6624-4de1-daad-4fe9b3d723a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7854b0b037c0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START , 'Chatbot')\n",
        "graph_builder.add_edge('Chatbot' , END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrF9aWyjvOWy",
        "outputId": "c7c96255-933d-41b2-b37a-cf6b8ef457fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7854b0b037c0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "2x6t-ZfmvSkQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "Q0DbwKazvfmx",
        "outputId": "fb47e8bb-0a9a-404c-e2e6-c08cb5c71ba3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADqAGsDASIAAhEBAxEB/8QAHQABAAMBAAMBAQAAAAAAAAAAAAUGBwQCAwgBCf/EAE8QAAEDAwEDBA0FDQUJAAAAAAECAwQABREGBxIhEzFBlAgUFRYiMlFUVmGB0dMXI1VxlSU0NkJSYnN1kZKTssIkU3J00iY1Q0RGg7HB8P/EABoBAQEAAwEBAAAAAAAAAAAAAAABAgMEBwX/xAAzEQACAQICBgcJAAMAAAAAAAAAAQIDEQQxEhQhUXGRE1JhYpKh0SIjMjNBU4GxweHw8f/aAAwDAQACEQMRAD8A/qnSlQV2u0uTcBaLSEiWEhcmY4N5uIg83D8ZxX4qeYAFSuG6lecYubsi5ky/IajNlx5xDSBzqWoJA9pqPOqbKDg3eAD/AJlHvrgZ2f2UrD1wii9zMYVKuoD6zxzwBG6j6kJSPVXcNK2UDHceBj/Ko91bbUVm2xsP3vqsv0xA6yj3076rL9MQOso99O9Wy/Q8DqyPdTvVsv0PA6sj3U9z2+Rdg76rL9MQOso99O+qy/TEDrKPfTvVsv0PA6sj3U71bL9DwOrI91Pc9vkNg76rL9MQOso99O+qy/TEDrKPfTvVsv0PA6sj3U71bL9DwOrI91Pc9vkNh0w7tBuBIizI8kjoZdSv/wAGuuoKZoTTk8fPWO3qV0OJjIStPrSoAEH1g1xuomaLBfS/JuljB+eafVyj8NP5aFeM4gc5SoqUBkgnATTQhPZB7dz9f+EsnkWmleLbiHm0uNqStCgFJUk5BB5iDXlXOQ9ch9EZhx5w4Q2krUfIAMmoDZ+yo6Yi3B4Dty6jujIUM8VuAEDj+SncQPUgVNXKJ2/bpUXOOXaW3nyZBH/uorQUrtvRdlWQUuIiNtOJUMFLiBuLSR6lJI9ldC2UXbev6X6E9SlK5yFd11tB0/s1sYu+pLgLdBU8iM2oNLdcddWcIbbbbSpa1HBwlIJ4HyVm+suym0zpids/VGZn3O06qkSmzMj2yYtyOhlt0qIZQwpal8o2EFGAoDeURhJNTfZC2m0XbREQXe1aluAj3JiTEk6SjqeuFukICiiU2lOT4PEHCVePgpIJrIzO2gu6e2P631bp69XiTp7UM8zWods+6a4LseTHjyXYjeSlZC2ytCRkb2cDiABs+s+yC0Fs9uceBqG+Ltkh6O3K+cgSVNstLJCFvLS2UsgkEZcKeY+SvfqfbnorR+pkaduV3d7uORGpzcCHAky3XGHFrQlxKWW17yctqyR4uAVYBBOC7cxqvaBcda22XaNev2q56caRpS12Jl6NFdeejr5bugtJSErS4UpLT6gncBwlRJq4bFNP3RO12BeptkuMJj5N7NA7ZnQnGdyQl98usEqSMOJ8AqRzjwT0igLhst7IK1bTNbav001BnwplkujsFlbkCUGn222mlKcU6plLbat5xQDZVvEJChkKBrV6w/ZPIuGi9r+0jT1z09eko1BqBV6t94agrcty2FQmEkKkAbqFhTCk7qsEkpxnNbhQClKUBWNDYgtXWyJwGrRMMaOlOcJYU2h1pIz0JS4ED1Iqz1WdJJ7YvWqZ6c8k9cAy2SMZDTLbaj6/DDg9lWauiv8AMb4X422+ZXmKq7wVo25SpYbUuxTXC9I5NJUqG8cbzhA/4SsZUR4isqOUqUpFopWuE9G6e1MFV1Rs90ZtQYgSdQafs2qGWEqVEdnRW5KUJXjeKCoHAVupzjnwKgR2NuygJKfk30tukgkdyWME9H4vrNWWToK1uPuPw1S7O84SVqtklbCVEnJJbB3CSeOSnPPx4mvV3kyOjVN+H/eZ+FWzQpPKVuK9LjYeGkNlGi9n8x+XpnSlnsEp9vknXrbCbYWtGc7pKQMjIBxVrqr95Mj0qv38Zn4VO8mR6VX7+Mz8KnR0+v5MWW8tFKyzWNuutj1NoWBF1TeDHvN3dhS+VdZ3uTTAlvjc+bHhb7Dfl4b3DpFr7yZHpVfv4zPwqdHT6/kxZbyX1Bp216rs8m03q3RrrbJIAehzGkutOAEKAUlQIOCAfrAqko7G7ZS2SUbONLpJBGRaWBwIwR4vkNT/AHkyPSq/fxmfhU7yZHpVfv4zPwqdHT6/kxZbyJtGwHZpYLpFuVt0DpyBcIriXmJUa2MocaWDkKSoJyCD0ip67X9yTJctNkW3Iuud113xmoKTzrd/Ox4rfOo45k7yk850EzI4Tbzep7Z4FpycppKvr5LcyPVzHpqet1siWiIiLCjNRI6ckNsoCRk854dJ6T0093DanpPyGxHhZrTHsVqi2+KFBiOgISVneUryqUelROST0kk120pWhtyd3mQUpSoBSlKAUpSgM/2kFI1zsp3iQTqKRu4HOe5Fw9Y6M+X6ukaBWf7SM9/GynBTjvhkZ3gM/wC6LhzZ45+rjjPRmtAoBSlKAUpSgFKUoBSlKAUpSgFKUoDPdpQB11snypKcajkYChxV9yLjwHDn6ejmP1VoVZ7tLx39bJskg98cjHg5z9x7j+z/AO8taFQClKUApSlAKUpQClKq141XONwfgWOCxNejEJkyJb6mmW1EAhA3UKK1YIJHAAEcc8K2U6cqjtEtrlppVI7u6w8wsfW3vh07u6w8wsfW3vh10arPeuaFi70qkd3dYeYWPrb3w6d3dYeYWPrb3w6arPeuaFj5R7Jrs3JmybbVaNPXTZ2685pq5KuMaQ3dRu3Bl2HIYQpILB3D/aMnBOChScnia+ztIXqRqTSdku0y3rtMufBYlPQHF76oy1tpUpoqwMlJJTnAzjmFYBtj7H97bXrrReqL3b7MmZpuRyhbRIcUma0DvpZcy14oWN7h+UodORr/AHd1h5hY+tvfDpqs965oWLvSqR3d1h5hY+tvfDp3d1h5hY+tvfDpqs965oWLvSqR3d1h5hY+tvfDryTqfU0L56baLfJjJ4uJgS3C8E9JQlTYCj6sj1ceFNVqb1zQsXWleiBOYucKPMiuB6M+2l1txPMpJGQf2V765GmnZkFZ/pjjL1Eek3Z/j7EitArP9L/fWov1vI/prtw3wz/H7MlkydpSqRr/AG06M2YTYkLUd6TDny0F1mExHelSFIBwV8kyhagnPDeIA4HjwrZkYl3pVYsu0vTeornabfb7l2zLutsVeIbYYcTysRKkILuSkAeE4gbpIV4XNwNWegFK4brfLfY0RlXGaxCTKkNxGC+4Ecq8s4Q2nPOpR5gONcqNXWlerndLpl5vrUFFyXF5NfCOpxTaV7+N3itChjOeGcYoCYpSuG6Xy32QwxcJrEMzJCYkYPuBJeeUCUtoz4yiEqOBxwCeiqDupSlAejZcf9gLL6mSB6hvGrVVV2W/gBZv0R/mNWquTE/Pnxf7K82Kz/S/31qL9byP6a0Cs/0v99ai/W8j+mt2G+Gf4/ZVkydrDdjqo6+yE22G4FPfEmVb0shzxxbu1U8lyefxN8uZxw3ufjityqja+2IaJ2nXGLcdR2NMy4xWyy1NYkPRXw2TktlxlaFKRkk7pJHE8ONZtGJnG0LS7WvOyd03CF7ulqjnR9wcW/Y5pjPOATIo3OVT4SRkgndIOUgE4yDTbdrC86w2eaN0q7cdTXrV790vEOO7bL13JVKjwZK2S9LlISVABJa8RJKlHmPGvojT+yzSulbjap1nszNukWu3OWqH2upaUNRluJcWgIzunK0JUVEFWQePE5iZ+wTQtytcO3vWRSWIcyTPjrYnSGXmnpC1LfKXUOBYC1KOU726eAxgADHRYPnCeq6bQdj2zpnVN1ua7lbNpCLE5Kj3RxDq0ImONJKnm9zfcSlKQl3dCsjeGCo1f73szY1J2SblkGotS2lmFoOGhEu23d1qW4RNkJSpx8krcI5/CJ3jxVmtTb2D6Da0bcNKN6dZa09OlCc7AbddShL43cONkKy0coSfmynjk85JPBd+xv2e33tVU6ySH3Y0NNvbkd1ZiXu10rccDanA6FKSVOrJ3id7IzndTiaLBiuz/WWqNrszZ/pC96ouUK3rjXp2TeLPIMKRelQpiYzOHW8KSNxRcVuEbxHkqGvzErWsLS9lvN/vVwa07tXXpyLdG7k6xIejdrrWkuONqTvPIJ5MO+MN1WCCpWfpm+7F9Faj07Z7HLsLLdts+O5yITrkRcPwd35pxlSVoyOBwoZ6c1+SNieiJOg2NGq0+wjTjDqX2ojTjjam3QrfDqXUqDgc3iTvhW8STk8TTRYLdbYKLXbosNtx55uO0hlLkl5TzqgkAArWolS1HHFRJJPE101w2OyxNOWiJbICHG4cVsNNJdeW6oJHlWslSj6ySa7q2A9Gy38ALN+iP8xq1VVdlv4AWb9Ef5jVqrlxPz58X+yvNis/0v8AfWov1vI/prQKpdytN0sFznSrZbzd4c53thyO08ht5l3dSlW7vkJUlW7nxgQc+MD4O3DSXtRbtcq3EjSoTutfvQy69ahfHp3Wv3oZdetQvj11aHeXiXqLE3SoTutfvQy69ahfHp3Wv3oZdetQvj00O8vEvUWJulVO6a3n2afaIUzSl1ak3aSqHCRy8RXKupZcfKch4hPzbLisnA8HHOQDI91r96GXXrUL49NDvLxL1FibpUJ3Wv3oZdetQvj07rX70MuvWoXx6aHeXiXqLE3SoTutfvQy69ahfHryRJ1JPPIsabdtri+HbNxksFpv87dacWpWOfd4ZxjeTnIaHeXiXqSxJbLfwAs36I/zGrVXBYrOzp+zQrawpS2orSWgtw5UvA4qPrPOfrrvr51aSnUlJZNsPaxSlK0kFKUoBSlKAoO0VOdbbLDjONQSDndzj7kz/UcftH18cG/Vn+0hG9rnZSd1R3dRSDkJyB9yLgMnjw5+fjzjy5rQKAUpSgFKUoBSlKAUpSgFKUoBSlKAz3aUUjXWybJwTqORjwQcnuPcf2fX7OmtCqgbRws642VbpcAGoZG9uDII7k3DxvIM49uKv9AKUpQClKUApSlAKUpQClfilBCSpRCUgZJJwAKrknaVpKI6pt7U9nbcScKQZzWU/WN7hWyFOdT4E3wLZvIslKqvyq6N9KrP11v30+VXRvpVZ+ut++tmrV+o+TLovcUDahtU0RF2g7OWJGr7AzItuopPbbTlzYSqKRa57Z5QFYKPCUE+EOdQGMnhsUGdGukKPMhyGpcOQ2l5mQwsLbdQoZSpKhwIIIII4EGv5wdmdsCse0rb5pe/6UvdrMDUzyI18fYktlEJaMAyV4OAlTY9qkHpUM/dem9a7P8ASenbXY7bqWzsW62RWoUZrt5s7jTaAhA5+hKRTVq/UfJjRe4vdKqvyq6N9KrP11v31+japo0n8KrMPWZzYH81NWr9R8mTRe4tNK47ZeIF6j8vbpsaex/exnUuJ/akkV2VoacXZkFKUqAVG6j1BD0tZ5FynKUlhkDwUDK1qJwlCR0qJIA+upKsZ253Rci/2W0hWGGGXJziPylk8m2fYOV/eHkruwWH1qvGk8vrwRUU/VGo7jraUt26uHtQqJatqFnkG09G8OZxX5yhz5wEjhUchtLSQlCQhI5gkYAr9pXo8IRpRUIKyRg22KUqg3rbPabLLuINsvE22Wxwsz7xDiByJFWnG+FK3go7mfCKEqCeOeINSdSNNXk7EL9Ss8ve221WaffYybRebk3Yw25cJUGMhbLLS2Uuh3eKxvJ3VcQkFXgk7uME91+2r2y0XOHboUC56inSIonchZo4dU1HPBLqypSQArjgZKjg4FYdPT27cgXWlUnYrqS4au2W6evF1kGVcJbBW88W0o3jvqHipAA4Acwq7VshNVIqaye0HhHbMGYmZDccgzUkESYquTc+okc49RyD0its2Z7RFaoQq2XLcRemG+U3kDdTJbBA5RI6CCUhQ6CQRwOBi1eyDdF2G9Wq6tq3FRJbSlHytqUEOJ9qFK9uPJXDjsHDF0mmvaWT/nAzTvsZ9RUpSvOAKxTbjAXG1XZ55CizKiORd7oStCt9I+shayP8Bra6g9Y6UjaysTtukKLSshxh9KcqZdT4qwOnyEdIJHTX0MBiFhcRGpLL6/kqPnRa0tIUtaghCRlSlHAA8pqqfK7oU/8AWmnvtVj/AF1crxbpenLkbbdmRFlkkI4/NvpH4zavxh6ucZwQK4+0Yx/5dr9wV6HdzSlTas/z/TC1is/K7oX01079qsf66yyBslVZdQXpiZs2tGs4txujs6NfXnY6S2y8vfUh0OArJQSrBSFBQxzVvPaUf+4a/cFe6tU6HS2dR5dnrcGVvaEuyF7XEMQEoYvcRtm1pS4gB7dgBndAz4GFjd8LHl5uNRundN6t2eagZuULTovzF0sluhzGkTWmXYUiM2pPErOFIIWclJJyOY9OzUqPDRupJtNX823u7WDLNl98tOy/Z1p7Turb1aNP3yLGJegzbkwlaMrUQfH4g+UVZ/ld0L6a6d+1WP8AXVocjMuq3ltIWryqSCa8e0Y3m7X7grOMJwioRasuz/IOOxaltGqIzkizXWFdo7a+TW7BkIeSlWAd0lJIBwQceupJuAu73C3W1oFTk2WywAnnCd8FZ9iAtX1A16SpiHuIAS2XFBKG0J8JajzBKRxJ9QrYNlezx+1Pi/Xdrkp6my3GiKwTHQrnUr89QA/wjI6VVoxeKjhKLnN+19O1/wC5mUd5plKUrzYClKUByXS0wb3DXEuENidFX4zMhsOIPsPCqg9sS0e6oqFvksZ/FYuMltPsSlwAewVeqVvp4itR2U5tcG0W7RQfkN0j5rP+1pfxafIbpHzWf9rS/i1fqVv17FfdlzYuyg/IbpHzWf8Aa0v4tPkN0j5rP+1pfxav1Ka9ivuy5sXZQfkN0j5rP+1pfxa/RsO0gDxiTyPIbtL+LV9pTXsV92XNi7IHT2g9P6VcLtrtTEZ8jdMggreI8hcUSoj21PUpXJOcqj0pu77SZilKVgD/2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask Question To The Bot Outside Its Training Data"
      ],
      "metadata": {
        "id": "G_Br5ViyvwdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"User: \")\n",
        "  if user_input.lower() in ['quit' , 'exit' , 'q']:\n",
        "    print(\"GoodBye\")\n",
        "    break\n",
        "\n",
        "  for event in graph.stream({'message':('user', user_input)}):\n",
        "    print(event.values())\n",
        "    for values in event.values():\n",
        "      print(values['message'])\n",
        "      print('Assitant:' , values['message'].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHqbX2-3v3_d",
        "outputId": "5ebcbed2-45ba-46ca-c33a-36e363f2bb08"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: hey\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=7c692a1f-0c62-4fe5-a021-74dd0341f8db; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=f4d0d2a0-49b1-4497-8969-124c8555e260; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=56add05f-c684-46cd-b1f6-c90623e169fb; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=ad264968-d3bf-44c7-af7d-30bdeb54ee6a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([{'message': AIMessage(content='Hey there! 👋 What can I do for you today? 😊\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 10, 'total_tokens': 26, 'completion_time': 0.029090909, 'prompt_time': 4.5e-07, 'queue_time': 0.012866269999999999, 'total_time': 0.029091359}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ad264968-d3bf-44c7-af7d-30bdeb54ee6a-0', usage_metadata={'input_tokens': 10, 'output_tokens': 16, 'total_tokens': 26})}])\n",
            "content='Hey there! 👋 What can I do for you today? 😊\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 10, 'total_tokens': 26, 'completion_time': 0.029090909, 'prompt_time': 4.5e-07, 'queue_time': 0.012866269999999999, 'total_time': 0.029091359}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-ad264968-d3bf-44c7-af7d-30bdeb54ee6a-0' usage_metadata={'input_tokens': 10, 'output_tokens': 16, 'total_tokens': 26}\n",
            "Assitant: Hey there! 👋 What can I do for you today? 😊\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=7c692a1f-0c62-4fe5-a021-74dd0341f8db; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=f4d0d2a0-49b1-4497-8969-124c8555e260; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=56add05f-c684-46cd-b1f6-c90623e169fb; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=ad264968-d3bf-44c7-af7d-30bdeb54ee6a\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=7c692a1f-0c62-4fe5-a021-74dd0341f8db; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=f4d0d2a0-49b1-4497-8969-124c8555e260; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=56add05f-c684-46cd-b1f6-c90623e169fb; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=ad264968-d3bf-44c7-af7d-30bdeb54ee6a\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=f0cd29a5-a37f-48c6-b520-804741c2b0cf; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=7c692a1f-0c62-4fe5-a021-74dd0341f8db; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=56add05f-c684-46cd-b1f6-c90623e169fb; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=ad264968-d3bf-44c7-af7d-30bdeb54ee6a\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=f0cd29a5-a37f-48c6-b520-804741c2b0cf; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=7c692a1f-0c62-4fe5-a021-74dd0341f8db; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=56add05f-c684-46cd-b1f6-c90623e169fb; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=ad264968-d3bf-44c7-af7d-30bdeb54ee6a\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=f0cd29a5-a37f-48c6-b520-804741c2b0cf; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=7c692a1f-0c62-4fe5-a021-74dd0341f8db; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=56add05f-c684-46cd-b1f6-c90623e169fb; trace=7c692a1f-0c62-4fe5-a021-74dd0341f8db,id=ad264968-d3bf-44c7-af7d-30bdeb54ee6a\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: what is generative ai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=858659c5-671c-42e9-a567-5c5a702c7f0c; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=44a90bb1-60df-48f5-b3f1-a8d60f3d7cea; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=28b97571-e74d-4446-8653-8994b55fabaa; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=14aff01d-53c3-4067-97f8-c3e533b13e83\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=858659c5-671c-42e9-a567-5c5a702c7f0c; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=44a90bb1-60df-48f5-b3f1-a8d60f3d7cea; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=28b97571-e74d-4446-8653-8994b55fabaa; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=14aff01d-53c3-4067-97f8-c3e533b13e83\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=858659c5-671c-42e9-a567-5c5a702c7f0c; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=44a90bb1-60df-48f5-b3f1-a8d60f3d7cea; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=28b97571-e74d-4446-8653-8994b55fabaa; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=14aff01d-53c3-4067-97f8-c3e533b13e83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([{'message': AIMessage(content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of just analyzing existing data, generative AI learns the patterns and structures within that data and then uses that knowledge to generate something completely new. \\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates text:**  Writing stories, poems, articles, dialogue, and even code.\\n* **Generates images:**  Producing realistic photos, artwork, and illustrations.\\n* **Composes music:**  Crafting original melodies, harmonies, and entire musical pieces.\\n* **Designs objects:**  Coming up with new product designs, architectural blueprints, or even 3D models.\\n* **Summarizes and translates text:**  Condensing large amounts of information or converting it into different languages.\\n\\n**How it works:**\\n\\nGenerative AI models are typically trained on massive datasets of existing content. They learn the underlying rules and relationships within that data, allowing them to predict and generate new content that follows similar patterns.\\n\\n**Popular examples:**\\n\\n* **ChatGPT:** A text-based AI that can engage in conversations, write different kinds of creative content, and answer your questions in an informative way.\\n* **DALL-E 2:**  An AI system that can create realistic images from textual descriptions.\\n* **Jukebox:** An AI model developed by OpenAI that can generate music in various styles.\\n\\n**The potential:**\\n\\nGenerative AI has the potential to revolutionize many industries, from entertainment and design to healthcare and education. It can automate creative tasks, help us explore new ideas, and personalize our experiences.\\n\\n\\nLet me know if you have any other questions!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 354, 'prompt_tokens': 13, 'total_tokens': 367, 'completion_time': 0.643636364, 'prompt_time': 0.000225499, 'queue_time': 0.023781672, 'total_time': 0.643861863}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-14aff01d-53c3-4067-97f8-c3e533b13e83-0', usage_metadata={'input_tokens': 13, 'output_tokens': 354, 'total_tokens': 367})}])\n",
            "content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of just analyzing existing data, generative AI learns the patterns and structures within that data and then uses that knowledge to generate something completely new. \\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates text:**  Writing stories, poems, articles, dialogue, and even code.\\n* **Generates images:**  Producing realistic photos, artwork, and illustrations.\\n* **Composes music:**  Crafting original melodies, harmonies, and entire musical pieces.\\n* **Designs objects:**  Coming up with new product designs, architectural blueprints, or even 3D models.\\n* **Summarizes and translates text:**  Condensing large amounts of information or converting it into different languages.\\n\\n**How it works:**\\n\\nGenerative AI models are typically trained on massive datasets of existing content. They learn the underlying rules and relationships within that data, allowing them to predict and generate new content that follows similar patterns.\\n\\n**Popular examples:**\\n\\n* **ChatGPT:** A text-based AI that can engage in conversations, write different kinds of creative content, and answer your questions in an informative way.\\n* **DALL-E 2:**  An AI system that can create realistic images from textual descriptions.\\n* **Jukebox:** An AI model developed by OpenAI that can generate music in various styles.\\n\\n**The potential:**\\n\\nGenerative AI has the potential to revolutionize many industries, from entertainment and design to healthcare and education. It can automate creative tasks, help us explore new ideas, and personalize our experiences.\\n\\n\\nLet me know if you have any other questions!\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 354, 'prompt_tokens': 13, 'total_tokens': 367, 'completion_time': 0.643636364, 'prompt_time': 0.000225499, 'queue_time': 0.023781672, 'total_time': 0.643861863}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-14aff01d-53c3-4067-97f8-c3e533b13e83-0' usage_metadata={'input_tokens': 13, 'output_tokens': 354, 'total_tokens': 367}\n",
            "Assitant: Generative AI is a type of artificial intelligence that focuses on creating new content. \n",
            "\n",
            "Think of it like this: instead of just analyzing existing data, generative AI learns the patterns and structures within that data and then uses that knowledge to generate something completely new. \n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "**What it does:**\n",
            "\n",
            "* **Creates text:**  Writing stories, poems, articles, dialogue, and even code.\n",
            "* **Generates images:**  Producing realistic photos, artwork, and illustrations.\n",
            "* **Composes music:**  Crafting original melodies, harmonies, and entire musical pieces.\n",
            "* **Designs objects:**  Coming up with new product designs, architectural blueprints, or even 3D models.\n",
            "* **Summarizes and translates text:**  Condensing large amounts of information or converting it into different languages.\n",
            "\n",
            "**How it works:**\n",
            "\n",
            "Generative AI models are typically trained on massive datasets of existing content. They learn the underlying rules and relationships within that data, allowing them to predict and generate new content that follows similar patterns.\n",
            "\n",
            "**Popular examples:**\n",
            "\n",
            "* **ChatGPT:** A text-based AI that can engage in conversations, write different kinds of creative content, and answer your questions in an informative way.\n",
            "* **DALL-E 2:**  An AI system that can create realistic images from textual descriptions.\n",
            "* **Jukebox:** An AI model developed by OpenAI that can generate music in various styles.\n",
            "\n",
            "**The potential:**\n",
            "\n",
            "Generative AI has the potential to revolutionize many industries, from entertainment and design to healthcare and education. It can automate creative tasks, help us explore new ideas, and personalize our experiences.\n",
            "\n",
            "\n",
            "Let me know if you have any other questions!\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=aa31f536-ccf9-4b15-85dd-c2f7c3a92850; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=858659c5-671c-42e9-a567-5c5a702c7f0c; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=28b97571-e74d-4446-8653-8994b55fabaa; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=14aff01d-53c3-4067-97f8-c3e533b13e83\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=aa31f536-ccf9-4b15-85dd-c2f7c3a92850; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=858659c5-671c-42e9-a567-5c5a702c7f0c; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=28b97571-e74d-4446-8653-8994b55fabaa; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=14aff01d-53c3-4067-97f8-c3e533b13e83\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=aa31f536-ccf9-4b15-85dd-c2f7c3a92850; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=858659c5-671c-42e9-a567-5c5a702c7f0c; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=28b97571-e74d-4446-8653-8994b55fabaa; trace=858659c5-671c-42e9-a567-5c5a702c7f0c,id=14aff01d-53c3-4067-97f8-c3e533b13e83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: exit\n",
            "GoodBye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inB-m3Xtxawe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}